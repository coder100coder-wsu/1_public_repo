{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Regression in PySpark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dependencies\n",
    "## Install pyspark, pandas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [],
   "source": [
    "# !pip install pyspark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies/packages such as pyspark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [],
   "source": [
    "import pyspark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Spark Session"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('spark_project ').getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Change logging options, to suppress WARNings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Note: getOrCreate() is important.\n",
    "Otherwise you have to manually reset kernel everytime, and manually run cells in proper sequence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ALWAYS USE SPARK FUNCTIONS\n",
    "TO TAKE ADVANTAGE OF SPARK'S EXECUTION SPEED. STAY AWAY FROM USER-DEFINED FUNCTIONS IF POSSIBLE."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x269fd027d60>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>spark_project </code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SparkUI hyperlink available"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Wrangling, ETL process\n",
    "Get Data, part of"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "outputs": [],
   "source": [
    "# df_spark = spark.read.option('header','true').csv(\"file:///D:/2_R_repo/2_python repo/Spark project/auto-mpg.csv\", inferSchema=True)\n",
    "df_spark = spark.read.csv(\"file:///D:/2_general_repo/1_public_repo/Spark project/auto-mpg.csv\", inferSchema=True, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: without inferSchema, everything is type-string.\n",
    "df_spark.describe()\n",
    "DataFrame[summary: string, _c0: string, V1: string, V2: string, V3: string, V4: string, V5: string, V6: string, V7: string, V8: string, V9: string]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rename ALL columns\n",
    "toDF(*new_col_names)\n",
    "Can be used for multiple (as in less than all) columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "outputs": [],
   "source": [
    "new_col_names = [\"sr_no\", \"mpg\", \"cyl\", \"dspl\", \"hp\", \"wt\", \"accl\", \"yr\", \"origin\", \"name\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Without assignment OR without capturing return value of function, the result is only view, not modification to df.\n",
    "Also Spark uses RDD, immutable datastructures, so everytime a brand new datastructure is created"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [],
   "source": [
    "df_spark = df_spark.toDF(*new_col_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dimensions of dataset, shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [
    {
     "data": {
      "text/plain": "(225, 10)"
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_spark.count() , len(df_spark.columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Show data, .show()\n",
    "similar to pandas .head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---+-----+---+----+----+---+------+--------------------+\n",
      "|sr_no| mpg|cyl| dspl| hp|  wt|accl| yr|origin|                name|\n",
      "+-----+----+---+-----+---+----+----+---+------+--------------------+\n",
      "|    1|18.0|  8|307.0|130|3504|12.0| 70|     1|chevrolet chevell...|\n",
      "|    2|15.0|  8|350.0|165|3693|11.5| 70|     1|   buick skylark 320|\n",
      "|    3|18.0|  8|318.0|150|3436|11.0| 70|     1|  plymouth satellite|\n",
      "|    4|16.0|  8|304.0|150|3433|12.0| 70|     1|       amc rebel sst|\n",
      "|    5|17.0|  8|302.0|140|3449|10.5| 70|     1|         ford torino|\n",
      "+-----+----+---+-----+---+----+----+---+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.toDF(*new_col_names).show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get data_types in DataFrame, .dtypes()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [
    {
     "data": {
      "text/plain": "[('sr_no', 'int'),\n ('mpg', 'double'),\n ('cyl', 'int'),\n ('dspl', 'double'),\n ('hp', 'string'),\n ('wt', 'int'),\n ('accl', 'double'),\n ('yr', 'int'),\n ('origin', 'int'),\n ('name', 'string')]"
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Null value handling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[sr_no: int, mpg: double, cyl: int, dspl: double, hp: string, wt: int, accl: double, yr: int, origin: int, name: string]"
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.na.drop(how=\"all\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+----+---+---+----+---+------+----+\n",
      "|sr_no|mpg|cyl|dspl| hp| wt|accl| yr|origin|name|\n",
      "+-----+---+---+----+---+---+----+---+------+----+\n",
      "|    0|  0|  0|   0|  0|  0|   0|  0|     0|   0|\n",
      "+-----+---+---+----+---+---+----+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select( [ count( when( col(c).isNull(), c)).alias(c) for c in df_spark.columns]).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PIPELINE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Input Column list\n",
    "Define column lists that will be transformed, or converted to categorical variable from original data_type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "outputs": [],
   "source": [
    "input_col_list = ['cyl', 'yr']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorAssembler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize empty list of Stages in Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "outputs": [],
   "source": [
    "stages_list = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Append Stages, StringIndexer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Append Stages, IndexToString"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [],
   "source": [
    "for col in input_col_list:\n",
    "    # recast to string_index type from original type. ### Convert to String first.\n",
    "    # NOTE: It really converts to string_type that is indexed by frequency, max_frequency is given index 0.\n",
    "    stages_list.append(StringIndexer(inputCol=col, outputCol=col + '_str_ix', handleInvalid='skip'))\n",
    "    # recast to categorical variable from string_index\n",
    "    stages_list.append(IndexToString(inputCol=col + '_str_ix', outputCol=col + '_catg'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check partial pipeline output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---+-----+---+----+----+---+------+--------------------+----------+--------+---------+-------+\n",
      "|sr_no| mpg|cyl| dspl| hp|  wt|accl| yr|origin|                name|cyl_str_ix|cyl_catg|yr_str_ix|yr_catg|\n",
      "+-----+----+---+-----+---+----+----+---+------+--------------------+----------+--------+---------+-------+\n",
      "|    1|18.0|  8|307.0|130|3504|12.0| 70|     1|chevrolet chevell...|       1.0|       8|      3.0|     70|\n",
      "|    2|15.0|  8|350.0|165|3693|11.5| 70|     1|   buick skylark 320|       1.0|       8|      3.0|     70|\n",
      "+-----+----+---+-----+---+----+----+---+------+--------------------+----------+--------+---------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assemble pipeline\n",
    "pipeline = Pipeline(stages=stages_list)\n",
    "# Estimator fit\n",
    "pipeline_model = pipeline.fit(df_spark)\n",
    "# Transformer fit\n",
    "df_spark_updated = pipeline_model.transform(df_spark)\n",
    "df_spark_updated.show(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Append Stages, VectorAssembler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select features using column names list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "outputs": [],
   "source": [
    "predictor_cols = [\"dspl\", \"wt\", \"accl\" ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform DataFrame with vector-assembled features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "outputs": [],
   "source": [
    "stages_list.append(VectorAssembler(inputCols=[col for col in predictor_cols], outputCol='features'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: VectorAssembler_object.transform(DataFrame) returns a new DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: outputCol in VectorAssembler is the name of column,\n",
    "containing \"vector\" of input or independent features or predictors.\n",
    "It is added as a new column to original dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Form Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---+-----+---+----+----+---+------+--------------------+----------+--------+---------+-------+-------------------+\n",
      "|sr_no| mpg|cyl| dspl| hp|  wt|accl| yr|origin|                name|cyl_str_ix|cyl_catg|yr_str_ix|yr_catg|           features|\n",
      "+-----+----+---+-----+---+----+----+---+------+--------------------+----------+--------+---------+-------+-------------------+\n",
      "|    1|18.0|  8|307.0|130|3504|12.0| 70|     1|chevrolet chevell...|       1.0|       8|      3.0|     70|[307.0,3504.0,12.0]|\n",
      "|    2|15.0|  8|350.0|165|3693|11.5| 70|     1|   buick skylark 320|       1.0|       8|      3.0|     70|[350.0,3693.0,11.5]|\n",
      "+-----+----+---+-----+---+----+----+---+------+--------------------+----------+--------+---------+-------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assemble pipeline\n",
    "pipeline = Pipeline(stages=stages_list)\n",
    "# Estimator fit\n",
    "pipeline_model = pipeline.fit(df_spark)\n",
    "# Transformer fit\n",
    "df_spark_updated = pipeline_model.transform(df_spark)\n",
    "df_spark_updated.show(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "outputs": [],
   "source": [
    "lm_model = LinearRegression(featuresCol='features', labelCol='mpg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "outputs": [],
   "source": [
    "stages_list.append(LinearRegression(featuresCol='features', labelCol='mpg'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StringIndexer_47f1ac54a4e5, IndexToString_359293c2d6ac, StringIndexer_f76956302d01, IndexToString_c02fcede1809, VectorAssembler_41211c03b1fd, LinearRegression_612a1e4f892a]\n"
     ]
    }
   ],
   "source": [
    "print(stages_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---+-----+---+----+----+---+------+--------------------+----------+--------+---------+-------+-------------------+------------------+\n",
      "|sr_no| mpg|cyl| dspl| hp|  wt|accl| yr|origin|                name|cyl_str_ix|cyl_catg|yr_str_ix|yr_catg|           features|        prediction|\n",
      "+-----+----+---+-----+---+----+----+---+------+--------------------+----------+--------+---------+-------+-------------------+------------------+\n",
      "|    1|18.0|  8|307.0|130|3504|12.0| 70|     1|chevrolet chevell...|       1.0|       8|      3.0|     70|[307.0,3504.0,12.0]|17.375689672172097|\n",
      "|    2|15.0|  8|350.0|165|3693|11.5| 70|     1|   buick skylark 320|       1.0|       8|      3.0|     70|[350.0,3693.0,11.5]|15.903179717661235|\n",
      "+-----+----+---+-----+---+----+----+---+------+--------------------+----------+--------+---------+-------+-------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assemble pipeline\n",
    "pipeline = Pipeline(stages=stages_list)\n",
    "# Estimator fit\n",
    "pipeline_model = pipeline.fit(df_spark)\n",
    "# Transformer fit\n",
    "df_spark_updated = pipeline_model.transform(df_spark)\n",
    "df_spark_updated.show(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOTE: Train-test split is done later. Above results are using 100% of data as training data and predicting using model on the same data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop extra columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+------------------+\n",
      "| mpg|           features|        prediction|\n",
      "+----+-------------------+------------------+\n",
      "|18.0|[307.0,3504.0,12.0]|17.375689672172097|\n",
      "|15.0|[350.0,3693.0,11.5]|15.903179717661235|\n",
      "+----+-------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_list_to_drop = (\"cyl\", \"yr\", \"cyl_str_ix\", \"yr_str_ix\", \"name\", \"origin\", \"dspl\", \"hp\", \"wt\", \"accl\",\"cyl_catg\", \"yr_catg\")\n",
    "df_spark_updated = df_spark_updated.drop(*col_list_to_drop)\n",
    "df_spark_updated.show(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mpg: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_updated.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Refer above code to know that \"input_features\" is vector of predictor_cols = [\"dspl\", \"wt\", \"accl\" ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train-Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [],
   "source": [
    "train_data, test_data = df_spark_updated.randomSplit([0.75,0.25], seed=2022)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [
    {
     "data": {
      "text/plain": "167"
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [
    {
     "data": {
      "text/plain": "58"
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [
    {
     "data": {
      "text/plain": "225"
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_updated.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get RMSE\n",
    "Root Mean Squared Error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=  2.544\n"
     ]
    }
   ],
   "source": [
    "rmse_lm = round(model_lm_fit_train_data.summary.rootMeanSquaredError,3)\n",
    "print(\"RMSE= \", rmse_lm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get MAE\n",
    "Mean Absolute Error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE=  2.007\n"
     ]
    }
   ],
   "source": [
    "mae_lm = round(model_lm_fit_train_data.summary.meanAbsoluteError,3)\n",
    "print(\"MAE= \", mae_lm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get R-squared"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2=  0.81\n"
     ]
    }
   ],
   "source": [
    "r2_lm = round(model_lm_fit_train_data.summary.r2, 3)\n",
    "print(\"R2= \", r2_lm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get coefficients for fitted model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_coeff=  [-0.014, -0.004, -0.002]\n"
     ]
    }
   ],
   "source": [
    "model_coeff = model_lm_fit_train_data.coefficients\n",
    "print(\"model_coeff= \", [round(i,3) for i in model_coeff])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: \"input_features\" is vector of inputCols=['cyl', 'dspl', 'wt'].\n",
    "So coefficients above are 3-qty.total, 1 for each of the 3 predictors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Intercept for fitted model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_intercept=  36.422\n"
     ]
    }
   ],
   "source": [
    "model_intercept = round(model_lm_fit_train_data.intercept,3)\n",
    "print(\"model_intercept= \", model_intercept)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make Predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [],
   "source": [
    "yhat_model_predicts = model_lm_fit_train_data.evaluate(dataset= test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.ml.regression.LinearRegressionSummary at 0x26997530130>"
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_model_predicts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+------------------+\n",
      "| mpg|           features|        prediction|\n",
      "+----+-------------------+------------------+\n",
      "|10.0|[307.0,4376.0,15.0]|13.528052988819656|\n",
      "|10.0|[360.0,4615.0,14.0]| 11.78815738494092|\n",
      "|12.0|[350.0,4456.0,13.5]|12.604154192494484|\n",
      "+----+-------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\lib\\site-packages\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "yhat_model_predicts.predictions.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "outputs": [],
   "source": [
    "yhat_model_predicts_2 = model_lm_fit_train_data.transform(dataset= test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+------------------+\n",
      "| mpg|           features|        prediction|\n",
      "+----+-------------------+------------------+\n",
      "|10.0|[307.0,4376.0,15.0]|13.528052988819656|\n",
      "|10.0|[360.0,4615.0,14.0]| 11.78815738494092|\n",
      "|12.0|[350.0,4456.0,13.5]|12.604154192494484|\n",
      "+----+-------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat_model_predicts_2.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [],
   "source": [
    "lm_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"mpg\", metricName=\"r2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [
    {
     "data": {
      "text/plain": "pyspark.ml.evaluation.RegressionEvaluator"
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( lm_evaluator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.854\n"
     ]
    }
   ],
   "source": [
    "r2_lm_test = round(lm_evaluator.evaluate(yhat_model_predicts_2),3)\n",
    "print(\"R Squared (R2) on test data = %g\" %r2_lm_test )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on TRAIN data =  0.81\n"
     ]
    }
   ],
   "source": [
    "r2_lm_train = round(model_lm_fit_train_data.summary.r2, 3)\n",
    "print(\"R Squared (R2) on TRAIN data = \", r2_lm_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data =  2.485\n"
     ]
    }
   ],
   "source": [
    "rmse_lm_test = round(model_lm_fit_train_data.evaluate(test_data).rootMeanSquaredError,3)\n",
    "print(\"RMSE on test data = \", rmse_lm_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on TRAIN data =  2.544\n"
     ]
    }
   ],
   "source": [
    "rmse_lm_train = round(model_lm_fit_train_data.summary.rootMeanSquaredError,3)\n",
    "print(\"RMSE on TRAIN data = \", rmse_lm_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}